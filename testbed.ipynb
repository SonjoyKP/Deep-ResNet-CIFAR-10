{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available (for M1 Macs)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\" This script defines the ResNet18.\n",
    "\"\"\"\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = activation_func(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, last_activation=None, use_residual = True, use_bn = True):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.last_activation = last_activation\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = activation_func(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        if self.last_activation is not None:\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.xavier_normal_(m.weight) \n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        if self.last_activation == 'sigmoid':\n",
    "            x = self.sigmoid(x)\n",
    "        elif self.last_activation == 'none' or self.last_activation==None:\n",
    "            x = x   \n",
    "        elif self.last_activation == 'l2':\n",
    "            x= F.normalize(x,dim=0,p=2)               \n",
    "        else:\n",
    "            x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    \"\"\"\n",
    "    global activation_func\n",
    "    activation_func = nn.ReLU\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageUtils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\" This script implements the functions for data augmentation and preprocessing.\n",
    "\"\"\"\n",
    "\n",
    "def parse_record(record, training):\n",
    "    \"\"\" Parse a record to an image and perform data preprocessing.\n",
    "\n",
    "    Args:\n",
    "        record: An array of shape [3072,]. One row of the x_* matrix.\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        image: An array of shape [3, 32, 32].\n",
    "    \"\"\"\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = record.reshape((3, 32, 32))\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth]\n",
    "    image = np.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    image = preprocess_image(image, training)\n",
    "\n",
    "    # Convert from [height, width, depth] to [depth, height, width]\n",
    "    image = np.transpose(image, [2, 0, 1])\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image, training):\n",
    "    \"\"\" Preprocess a single image of shape [height, width, depth].\n",
    "\n",
    "    Args:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "    \n",
    "    Returns:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "    \"\"\"\n",
    "    # if training:\n",
    "        ### YOUR CODE HERE\n",
    "        # Resize the image to add four extra pixels on each side.\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        # Randomly crop a [32, 32] section of the image.\n",
    "        # HINT: randomly generate the upper left point of the image\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        # Randomly flip the image horizontally.\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # Subtract off the mean and divide by the standard deviation of the pixels.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    if training:\n",
    "        # 1. Pad the image with 4 pixels on each side (top, bottom, left, right)\n",
    "        image = np.pad(image, ((4, 4), (4, 4), (0, 0)), mode='constant')\n",
    "\n",
    "        # 2. Randomly crop a [32, 32] section of the image\n",
    "        x_start = np.random.randint(0, 9)  # Crop range in padded 40x40 image\n",
    "        y_start = np.random.randint(0, 9)\n",
    "        image = image[x_start:x_start+32, y_start:y_start+32, :]\n",
    "\n",
    "        # 3. Randomly flip the image horizontally\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "    \n",
    "    # 4. Per-channel normalization\n",
    "    mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "    std = np.std(image, axis=(0, 1), keepdims=True)\n",
    "    image = (image - mean) / (std + 1e-7)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from NetWork import resnet18\n",
    "#from ImageUtils import parse_record\n",
    "\n",
    "class Cifar(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Cifar, self).__init__()\n",
    "        self.config = config\n",
    "        # Initialize the network based on configuration settings\n",
    "        self.network = resnet18(use_residual=config.use_residual, use_bn=config.use_bn)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=1/1.5)\n",
    "        self.train_loss_history = []\n",
    "\n",
    "    def train(self, x_train, y_train, max_epoch):\n",
    "        self.network.train()\n",
    "        num_samples = x_train.shape[0]\n",
    "        num_batches = num_samples // self.config.batch_size\n",
    "\n",
    "        print('### Training... ###')\n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            start_time = time.time()\n",
    "            # Shuffle data at the start of each epoch\n",
    "            shuffle_index = np.random.permutation(num_samples)\n",
    "            curr_x_train = x_train[shuffle_index]\n",
    "            curr_y_train = y_train[shuffle_index]\n",
    "\n",
    "            epoch_loss = 0.0  # Track loss for the epoch\n",
    "\n",
    "            for i in range(num_batches):\n",
    "                start_idx = i * self.config.batch_size\n",
    "                end_idx = (i + 1) * self.config.batch_size\n",
    "                batch_x = np.array([parse_record(record, training=True) for record in curr_x_train[start_idx:end_idx]])\n",
    "                batch_y = curr_y_train[start_idx:end_idx]\n",
    "\n",
    "                # Convert to torch tensors and move to configured device\n",
    "                batch_x = torch.tensor(batch_x, dtype=torch.float32).to(self.config.device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.long).to(self.config.device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits = self.network(batch_x)\n",
    "                loss = self.loss_fn(logits, batch_y)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                print('Batch {:d}/{:d} Loss {:.6f}'.format(i + 1, num_batches, loss.item()), end='\\r', flush=True)\n",
    "\n",
    "            # Average loss for the epoch\n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            self.train_loss_history.append(avg_loss)\n",
    "            self.scheduler.step()  # Update learning rate per epoch\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            print('Epoch {:d} Loss {:.6f} Duration {:.3f} seconds.'.format(epoch, avg_loss, duration))\n",
    "\n",
    "            # Save model checkpoint at specified intervals\n",
    "            if epoch % self.config.save_interval == 0:\n",
    "                self.save(epoch)\n",
    "\n",
    "        # Plot the training loss curve\n",
    "        plt.plot(self.train_loss_history, label='Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def test_or_validate(self, x, y, checkpoint_num_list):\n",
    "        self.network.eval()\n",
    "        print('### Test or Validation ###')\n",
    "        for checkpoint_num in checkpoint_num_list:\n",
    "            checkpointfile = os.path.join(self.config.modeldir, 'model-%d.ckpt' % (checkpoint_num))\n",
    "            self.load(checkpointfile)\n",
    "\n",
    "            preds = []\n",
    "            with torch.no_grad():\n",
    "                for i in tqdm(range(x.shape[0])):\n",
    "                    # Preprocess the input record and make predictions\n",
    "                    record = parse_record(x[i], training=False)\n",
    "                    record = torch.tensor(record, dtype=torch.float32).unsqueeze(0).to(self.config.device)\n",
    "\n",
    "                    logits = self.network(record)\n",
    "                    pred = torch.argmax(logits, dim=1).item()\n",
    "                    preds.append(pred)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long).to(self.config.device)\n",
    "            preds_tensor = torch.tensor(preds, dtype=torch.long).to(self.config.device)\n",
    "            accuracy = torch.sum(preds_tensor == y_tensor).item() / y_tensor.size(0)\n",
    "            print('Checkpoint {} Test accuracy: {:.4f}'.format(checkpoint_num, accuracy))\n",
    "\n",
    "    def save(self, epoch):\n",
    "        checkpoint_path = os.path.join(self.config.modeldir, 'model-%d.ckpt' % (epoch))\n",
    "        os.makedirs(self.config.modeldir, exist_ok=True)\n",
    "        torch.save(self.network.state_dict(), checkpoint_path)\n",
    "        print(\"Checkpoint has been created.\")\n",
    "\n",
    "    def load(self, checkpoint_name):\n",
    "        ckpt = torch.load(checkpoint_name, map_location=self.config.device)\n",
    "        self.network.load_state_dict(ckpt, strict=True)\n",
    "        print(\"Restored model parameters from {}\".format(checkpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataReader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed.\n",
      "(50000, 3072) (50000,) (10000, 3072) (10000,)\n",
      "(45000, 3072) (45000,) (5000, 3072) (5000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "\"\"\" This script implements the functions for reading data.\n",
    "\"\"\"\n",
    "\n",
    "def extract_data(file_path, extract_dir):\n",
    "    \"\"\" Extracts the CIFAR-10 dataset if it's not already extracted.\n",
    "    \n",
    "    Args:\n",
    "        file_path: A string. The path to the cifar-10-python.tar.gz file.\n",
    "        extract_dir: A string. The directory where data should be extracted.\n",
    "    \"\"\"\n",
    "    if os.path.exists(extract_dir):\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_dir)\n",
    "            print(\"Extraction completed.\")\n",
    "    else:\n",
    "        print(\"Invalid Path\")\n",
    "    \n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Load the CIFAR-10 dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir: A string. The directory where data batches are stored.\n",
    "    \n",
    "    Returns:\n",
    "        x_train: An numpy array of shape [50000, 3072]. \n",
    "        (dtype=np.float32)\n",
    "        y_train: An numpy array of shape [50000,]. \n",
    "        (dtype=np.int32)\n",
    "        x_test: An numpy array of shape [10000, 3072]. \n",
    "        (dtype=np.float32)\n",
    "        y_test: An numpy array of shape [10000,]. \n",
    "        (dtype=np.int32)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    # Initialize empty lists to hold training data\n",
    "    x_train_list, y_train_list = [], []\n",
    "    \n",
    "    # Loop through data batches (1 to 5 are training batches)\n",
    "    for i in range(1, 6):\n",
    "        file_path = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            batch = pickle.load(file, encoding='bytes')\n",
    "            x_train_list.append(batch[b'data'])\n",
    "            y_train_list.extend(batch[b'labels'])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    x_train = np.concatenate(x_train_list, axis=0).astype(np.float32)\n",
    "    y_train = np.array(y_train_list, dtype=np.int32)\n",
    "    \n",
    "    # Load test data\n",
    "    test_file_path = os.path.join(data_dir, 'test_batch')\n",
    "    with open(test_file_path, 'rb') as file:\n",
    "        test_batch = pickle.load(file, encoding='bytes')\n",
    "        x_test = test_batch[b'data'].astype(np.float32)\n",
    "        y_test = np.array(test_batch[b'labels'], dtype=np.int32)\n",
    "    \n",
    "    # Normalize the data to [0, 1] range by dividing by 255.0\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_vaild_split(x_train, y_train, split_index=45000):\n",
    "    \"\"\" Split the original training data into a new training dataset\n",
    "        and a validation dataset.\n",
    "    \n",
    "    Args:\n",
    "        x_train: An array of shape [50000, 3072].\n",
    "        y_train: An array of shape [50000,].\n",
    "        split_index: An integer.\n",
    "\n",
    "    Returns:\n",
    "        x_train_new: An array of shape [split_index, 3072].\n",
    "        y_train_new: An array of shape [split_index,].\n",
    "        x_valid: An array of shape [50000-split_index, 3072].\n",
    "        y_valid: An array of shape [50000-split_index,].\n",
    "    \"\"\"\n",
    "    x_train_new = x_train[:split_index]\n",
    "    y_train_new = y_train[:split_index]\n",
    "    x_valid = x_train[split_index:]\n",
    "    y_valid = y_train[split_index:]\n",
    "\n",
    "    return x_train_new, y_train_new, x_valid, y_valid\n",
    "\n",
    "\n",
    "#wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# # Usage\n",
    "# file_path = '/home/grads/s/skpaul/Deep-ResNet-CIFAR-10/cifar-10-python.tar.gz'  # Update with the correct path\n",
    "# extract_dir = '/home/grads/s/skpaul/Deep-ResNet-CIFAR-10/dataset'  # Directory where you want to extract files\n",
    "\n",
    "# # Step 1: Extract the CIFAR-10 dataset\n",
    "# extract_data(file_path, extract_dir)\n",
    "\n",
    "# # Step 2: Load the data\n",
    "# data_dir = os.path.join(extract_dir, 'cifar-10-batches-py')  # Adjust if needed\n",
    "# x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "\n",
    "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "# print(x_train_new.shape, y_train_new.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 1, 5, 6], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Data ---\n",
      "cuda\n",
      "--- Starting Training ---\n",
      "### Training... ###\n",
      "Epoch 1 Loss 2.015007 Duration 10.252 seconds.\n",
      "Epoch 2 Loss 1.491353 Duration 9.894 seconds.\n",
      "Epoch 3 Loss 1.287714 Duration 9.895 seconds.\n",
      "Epoch 4 Loss 1.184388 Duration 10.314 seconds.\n",
      "Epoch 5 Loss 1.124677 Duration 10.043 seconds.\n",
      "Epoch 6 Loss 1.074880 Duration 10.344 seconds.\n",
      "Epoch 7 Loss 1.042967 Duration 10.172 seconds.\n",
      "Epoch 8 Loss 1.019354 Duration 10.512 seconds.\n",
      "Epoch 9 Loss 0.995538 Duration 10.382 seconds.\n",
      "Epoch 10 Loss 0.979812 Duration 10.246 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 11 Loss 0.893120 Duration 10.434 seconds.\n",
      "Epoch 12 Loss 0.882522 Duration 10.101 seconds.\n",
      "Epoch 13 Loss 0.869582 Duration 10.339 seconds.\n",
      "Epoch 14 Loss 0.856322 Duration 10.257 seconds.\n",
      "Epoch 15 Loss 0.852069 Duration 10.344 seconds.\n",
      "Epoch 16 Loss 0.841172 Duration 10.353 seconds.\n",
      "Epoch 17 Loss 0.834938 Duration 10.112 seconds.\n",
      "Epoch 18 Loss 0.825499 Duration 10.346 seconds.\n",
      "Epoch 19 Loss 0.821251 Duration 10.390 seconds.\n",
      "Epoch 20 Loss 0.813137 Duration 10.023 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 21 Loss 0.749650 Duration 10.301 seconds.\n",
      "Epoch 22 Loss 0.747388 Duration 9.878 seconds.\n",
      "Epoch 23 Loss 0.737002 Duration 10.205 seconds.\n",
      "Epoch 24 Loss 0.732987 Duration 10.273 seconds.\n",
      "Epoch 25 Loss 0.730598 Duration 9.877 seconds.\n",
      "Epoch 26 Loss 0.724757 Duration 10.573 seconds.\n",
      "Epoch 27 Loss 0.723683 Duration 10.417 seconds.\n",
      "Epoch 28 Loss 0.717960 Duration 10.246 seconds.\n",
      "Epoch 29 Loss 0.715041 Duration 9.687 seconds.\n",
      "Epoch 30 Loss 0.715280 Duration 10.316 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 31 Loss 0.659872 Duration 10.207 seconds.\n",
      "Epoch 32 Loss 0.652976 Duration 10.132 seconds.\n",
      "Epoch 33 Loss 0.647240 Duration 10.171 seconds.\n",
      "Epoch 34 Loss 0.641642 Duration 10.189 seconds.\n",
      "Epoch 35 Loss 0.647648 Duration 10.318 seconds.\n",
      "Epoch 36 Loss 0.645678 Duration 10.105 seconds.\n",
      "Epoch 37 Loss 0.638367 Duration 10.581 seconds.\n",
      "Epoch 38 Loss 0.631980 Duration 10.140 seconds.\n",
      "Epoch 39 Loss 0.633186 Duration 10.065 seconds.\n",
      "Epoch 40 Loss 0.630961 Duration 10.129 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 41 Loss 0.583759 Duration 9.770 seconds.\n",
      "Epoch 42 Loss 0.578585 Duration 10.226 seconds.\n",
      "Epoch 43 Loss 0.574747 Duration 10.376 seconds.\n",
      "Epoch 44 Loss 0.571630 Duration 10.189 seconds.\n",
      "Epoch 45 Loss 0.564770 Duration 10.086 seconds.\n",
      "Epoch 46 Loss 0.565733 Duration 9.938 seconds.\n",
      "Epoch 47 Loss 0.572603 Duration 10.480 seconds.\n",
      "Epoch 48 Loss 0.556996 Duration 10.440 seconds.\n",
      "Epoch 49 Loss 0.562395 Duration 10.159 seconds.\n",
      "Epoch 50 Loss 0.568409 Duration 10.154 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 51 Loss 0.526526 Duration 10.417 seconds.\n",
      "Epoch 52 Loss 0.523575 Duration 10.538 seconds.\n",
      "Epoch 53 Loss 0.517463 Duration 10.007 seconds.\n",
      "Epoch 54 Loss 0.512694 Duration 10.455 seconds.\n",
      "Epoch 55 Loss 0.509190 Duration 10.439 seconds.\n",
      "Epoch 56 Loss 0.511082 Duration 9.885 seconds.\n",
      "Epoch 57 Loss 0.508256 Duration 10.325 seconds.\n",
      "Epoch 58 Loss 0.508207 Duration 9.871 seconds.\n",
      "Epoch 59 Loss 0.505849 Duration 10.261 seconds.\n",
      "Epoch 60 Loss 0.504875 Duration 10.117 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 61 Loss 0.478733 Duration 10.141 seconds.\n",
      "Epoch 62 Loss 0.468286 Duration 10.401 seconds.\n",
      "Epoch 63 Loss 0.469117 Duration 10.227 seconds.\n",
      "Epoch 64 Loss 0.471917 Duration 9.806 seconds.\n",
      "Epoch 65 Loss 0.461318 Duration 10.488 seconds.\n",
      "Epoch 66 Loss 0.463108 Duration 10.389 seconds.\n",
      "Epoch 67 Loss 0.465140 Duration 10.117 seconds.\n",
      "Epoch 68 Loss 0.460980 Duration 10.437 seconds.\n",
      "Epoch 69 Loss 0.459453 Duration 10.365 seconds.\n",
      "Epoch 70 Loss 0.459281 Duration 10.412 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 71 Loss 0.436231 Duration 10.556 seconds.\n",
      "Epoch 72 Loss 0.434856 Duration 10.443 seconds.\n",
      "Epoch 73 Loss 0.430597 Duration 10.276 seconds.\n",
      "Epoch 74 Loss 0.427981 Duration 9.989 seconds.\n",
      "Epoch 75 Loss 0.430444 Duration 10.050 seconds.\n",
      "Epoch 76 Loss 0.426189 Duration 9.825 seconds.\n",
      "Epoch 77 Loss 0.424018 Duration 10.364 seconds.\n",
      "Epoch 78 Loss 0.421925 Duration 10.215 seconds.\n",
      "Epoch 79 Loss 0.422686 Duration 10.703 seconds.\n",
      "Epoch 80 Loss 0.426139 Duration 10.026 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 81 Loss 0.406789 Duration 10.173 seconds.\n",
      "Epoch 82 Loss 0.404465 Duration 10.290 seconds.\n",
      "Epoch 83 Loss 0.404374 Duration 10.216 seconds.\n",
      "Epoch 84 Loss 0.400984 Duration 10.269 seconds.\n",
      "Epoch 85 Loss 0.400160 Duration 10.172 seconds.\n",
      "Epoch 86 Loss 0.397843 Duration 9.990 seconds.\n",
      "Epoch 87 Loss 0.398311 Duration 10.291 seconds.\n",
      "Epoch 88 Loss 0.392458 Duration 10.577 seconds.\n",
      "Epoch 89 Loss 0.398549 Duration 10.294 seconds.\n",
      "Epoch 90 Loss 0.393768 Duration 9.998 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 91 Loss 0.386773 Duration 9.679 seconds.\n",
      "Epoch 92 Loss 0.380577 Duration 9.957 seconds.\n",
      "Epoch 93 Loss 0.380021 Duration 10.111 seconds.\n",
      "Epoch 94 Loss 0.374385 Duration 10.084 seconds.\n",
      "Epoch 95 Loss 0.377386 Duration 10.257 seconds.\n",
      "Epoch 96 Loss 0.377168 Duration 10.325 seconds.\n",
      "Epoch 97 Loss 0.378797 Duration 10.404 seconds.\n",
      "Epoch 98 Loss 0.377377 Duration 10.215 seconds.\n",
      "Epoch 99 Loss 0.372555 Duration 10.417 seconds.\n",
      "Epoch 100 Loss 0.374750 Duration 10.418 seconds.\n",
      "Checkpoint has been created.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validating on Validation Set ---\n",
      "### Test or Validation ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3889808/2409967368.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(checkpoint_name, map_location=self.config.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model parameters from model_v1/model-80.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 850.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 80 Test accuracy: 0.8046\n",
      "Restored model parameters from model_v1/model-90.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 864.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 90 Test accuracy: 0.8106\n",
      "Restored model parameters from model_v1/model-100.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 855.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 100 Test accuracy: 0.8136\n",
      "--- Testing on Test Set ---\n",
      "### Test or Validation ###\n",
      "Restored model parameters from model_v1/model-100.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 868.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 100 Test accuracy: 0.8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from ImageUtils import parse_record\n",
    "#from DataReader import load_data, train_vaild_split\n",
    "#from Model import Cifar\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "def configure():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Basic model and training parameters\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128, help='training batch size')\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=10, help='number of classes')\n",
    "    parser.add_argument(\"--save_interval\", type=int, default=10, help='save checkpoint every save_interval epochs')\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=2e-4, help='weight decay rate')\n",
    "    parser.add_argument(\"--modeldir\", type=str, default='model_v1', help='directory for saving models')\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01, help='learning rate')\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0, help='GPU ID to use')\n",
    "    parser.add_argument(\"--use_residual\", type=bool, default=True, help='whether to use residual connections')\n",
    "    parser.add_argument(\"--use_bn\", type=bool, default=True, help='whether to use batch normalization')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "# Parse command-line arguments and configure GPU visibility\n",
    "config = configure()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config.gpu)\n",
    "\n",
    "print(\"--- Preparing Data ---\")\n",
    "\n",
    "# Specify the path to the CIFAR-10 data directory\n",
    "data_dir = \"dataset/cifar-10-batches-py\"  # Update with the actual path to your CIFAR-10 data directory\n",
    "\n",
    "# Load and split the data into training, validation, and test sets\n",
    "x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and config.gpu >= 0 else \"cpu\")\n",
    "print(device)\n",
    "config.device = device\n",
    "\n",
    "# Initialize the Cifar model with the specified configuration and move it to the selected device\n",
    "model = Cifar(config).to(device)\n",
    "\n",
    "# Train the model for 100 epochs and validate with checkpoints at specified epochs\n",
    "print(\"--- Starting Training ---\")\n",
    "model.train(x_train_new, y_train_new, max_epoch=100)\n",
    "\n",
    "print(\"--- Validating on Validation Set ---\")\n",
    "model.test_or_validate(x_valid, y_valid, checkpoint_num_list=[80, 90, 100])\n",
    "\n",
    "print(\"--- Testing on Test Set ---\")\n",
    "model.test_or_validate(x_test, y_test, checkpoint_num_list=[100])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
