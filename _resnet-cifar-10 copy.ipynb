{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available (for M1 Macs)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\" This script defines the ResNet18.\n",
    "\"\"\"\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = activation_func(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, last_activation=None, use_residual = True, use_bn = True):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.last_activation = last_activation\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = activation_func(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        if self.last_activation is not None:\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.xavier_normal_(m.weight) \n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        if self.last_activation == 'sigmoid':\n",
    "            x = self.sigmoid(x)\n",
    "        elif self.last_activation == 'none' or self.last_activation==None:\n",
    "            x = x   \n",
    "        elif self.last_activation == 'l2':\n",
    "            x= F.normalize(x,dim=0,p=2)               \n",
    "        else:\n",
    "            x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    \"\"\"\n",
    "    global activation_func\n",
    "    activation_func = nn.ReLU\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageUtils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\" This script implements the functions for data augmentation and preprocessing.\n",
    "\"\"\"\n",
    "\n",
    "def parse_record(record, training):\n",
    "    \"\"\" Parse a record to an image and perform data preprocessing.\n",
    "\n",
    "    Args:\n",
    "        record: An array of shape [3072,]. One row of the x_* matrix.\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        image: An array of shape [3, 32, 32].\n",
    "    \"\"\"\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = record.reshape((3, 32, 32))\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth]\n",
    "    image = np.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    image = preprocess_image(image, training)\n",
    "\n",
    "    # Convert from [height, width, depth] to [depth, height, width]\n",
    "    image = np.transpose(image, [2, 0, 1])\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image, training):\n",
    "    \"\"\" Preprocess a single image of shape [height, width, depth].\n",
    "\n",
    "    Args:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "    \n",
    "    Returns:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "    \"\"\"\n",
    "    # if training:\n",
    "        ### YOUR CODE HERE\n",
    "        # Resize the image to add four extra pixels on each side.\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        # Randomly crop a [32, 32] section of the image.\n",
    "        # HINT: randomly generate the upper left point of the image\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        # Randomly flip the image horizontally.\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # Subtract off the mean and divide by the standard deviation of the pixels.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    if training:\n",
    "        # 1. Pad the image with 4 pixels on each side (top, bottom, left, right)\n",
    "        image = np.pad(image, ((4, 4), (4, 4), (0, 0)), mode='constant')\n",
    "\n",
    "        # 2. Randomly crop a [32, 32] section of the image\n",
    "        x_start = np.random.randint(0, 9)  # Crop range in padded 40x40 image\n",
    "        y_start = np.random.randint(0, 9)\n",
    "        image = image[x_start:x_start+32, y_start:y_start+32, :]\n",
    "\n",
    "        # 3. Randomly flip the image horizontally\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "    \n",
    "    # 4. Per-channel normalization\n",
    "    mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "    std = np.std(image, axis=(0, 1), keepdims=True)\n",
    "    image = (image - mean) / (std + 1e-7)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from NetWork import resnet18\n",
    "#from ImageUtils import parse_record\n",
    "\n",
    "class Cifar(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Cifar, self).__init__()\n",
    "        self.config = config\n",
    "        # Initialize the network based on configuration settings\n",
    "        self.network = resnet18(use_residual=config.use_residual, use_bn=config.use_bn)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=1/1.5)\n",
    "        self.train_loss_history = []\n",
    "\n",
    "    def train(self, x_train, y_train, max_epoch):\n",
    "        self.network.train()\n",
    "        num_samples = x_train.shape[0]\n",
    "        num_batches = num_samples // self.config.batch_size\n",
    "\n",
    "        print('### Training... ###')\n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            start_time = time.time()\n",
    "            # Shuffle data at the start of each epoch\n",
    "            shuffle_index = np.random.permutation(num_samples)\n",
    "            curr_x_train = x_train[shuffle_index]\n",
    "            curr_y_train = y_train[shuffle_index]\n",
    "\n",
    "            epoch_loss = 0.0  # Track loss for the epoch\n",
    "\n",
    "            for i in range(num_batches):\n",
    "                start_idx = i * self.config.batch_size\n",
    "                end_idx = (i + 1) * self.config.batch_size\n",
    "                batch_x = np.array([parse_record(record, training=True) for record in curr_x_train[start_idx:end_idx]])\n",
    "                batch_y = curr_y_train[start_idx:end_idx]\n",
    "\n",
    "                # Convert to torch tensors and move to configured device\n",
    "                batch_x = torch.tensor(batch_x, dtype=torch.float32).to(self.config.device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.long).to(self.config.device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits = self.network(batch_x)\n",
    "                loss = self.loss_fn(logits, batch_y)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                print('Batch {:d}/{:d} Loss {:.6f}'.format(i + 1, num_batches, loss.item()), end='\\r', flush=True)\n",
    "\n",
    "            # Average loss for the epoch\n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            self.train_loss_history.append(avg_loss)\n",
    "            self.scheduler.step()  # Update learning rate per epoch\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            print('Epoch {:d} Loss {:.6f} Duration {:.3f} seconds.'.format(epoch, avg_loss, duration))\n",
    "\n",
    "            # Save model checkpoint at specified intervals\n",
    "            if epoch % self.config.save_interval == 0:\n",
    "                self.save(epoch)\n",
    "\n",
    "        # Plot the training loss curve\n",
    "        plt.plot(self.train_loss_history, label='Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def test_or_validate(self, x, y, checkpoint_num_list):\n",
    "        self.network.eval()\n",
    "        print('### Test or Validation ###')\n",
    "        for checkpoint_num in checkpoint_num_list:\n",
    "            checkpointfile = os.path.join(self.config.modeldir, 'model-%d.ckpt' % (checkpoint_num))\n",
    "            self.load(checkpointfile)\n",
    "\n",
    "            preds = []\n",
    "            with torch.no_grad():\n",
    "                for i in tqdm(range(x.shape[0])):\n",
    "                    # Preprocess the input record and make predictions\n",
    "                    record = parse_record(x[i], training=False)\n",
    "                    record = torch.tensor(record, dtype=torch.float32).unsqueeze(0).to(self.config.device)\n",
    "\n",
    "                    logits = self.network(record)\n",
    "                    pred = torch.argmax(logits, dim=1).item()\n",
    "                    preds.append(pred)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long).to(self.config.device)\n",
    "            preds_tensor = torch.tensor(preds, dtype=torch.long).to(self.config.device)\n",
    "            accuracy = torch.sum(preds_tensor == y_tensor).item() / y_tensor.size(0)\n",
    "            print('Checkpoint {} Test accuracy: {:.4f}'.format(checkpoint_num, accuracy))\n",
    "\n",
    "    def save(self, epoch):\n",
    "        checkpoint_path = os.path.join(self.config.modeldir, 'model-%d.ckpt' % (epoch))\n",
    "        os.makedirs(self.config.modeldir, exist_ok=True)\n",
    "        torch.save(self.network.state_dict(), checkpoint_path)\n",
    "        print(\"Checkpoint has been created.\")\n",
    "\n",
    "    def load(self, checkpoint_name):\n",
    "        ckpt = torch.load(checkpoint_name, map_location=self.config.device)\n",
    "        self.network.load_state_dict(ckpt, strict=True)\n",
    "        print(\"Restored model parameters from {}\".format(checkpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataReader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "\"\"\" This script implements the functions for reading data.\n",
    "\"\"\"\n",
    "\n",
    "def extract_data(file_path, extract_dir):\n",
    "    \"\"\" Extracts the CIFAR-10 dataset if it's not already extracted.\n",
    "    \n",
    "    Args:\n",
    "        file_path: A string. The path to the cifar-10-python.tar.gz file.\n",
    "        extract_dir: A string. The directory where data should be extracted.\n",
    "    \"\"\"\n",
    "    if os.path.exists(extract_dir):\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_dir)\n",
    "            print(\"Extraction completed.\")\n",
    "    else:\n",
    "        print(\"Invalid Path\")\n",
    "    \n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Load the CIFAR-10 dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir: A string. The directory where data batches are stored.\n",
    "    \n",
    "    Returns:\n",
    "        x_train: An numpy array of shape [50000, 3072]. \n",
    "        (dtype=np.float32)\n",
    "        y_train: An numpy array of shape [50000,]. \n",
    "        (dtype=np.int32)\n",
    "        x_test: An numpy array of shape [10000, 3072]. \n",
    "        (dtype=np.float32)\n",
    "        y_test: An numpy array of shape [10000,]. \n",
    "        (dtype=np.int32)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    # Initialize empty lists to hold training data\n",
    "    x_train_list, y_train_list = [], []\n",
    "    \n",
    "    # Loop through data batches (1 to 5 are training batches)\n",
    "    for i in range(1, 6):\n",
    "        file_path = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            batch = pickle.load(file, encoding='bytes')\n",
    "            x_train_list.append(batch[b'data'])\n",
    "            y_train_list.extend(batch[b'labels'])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    x_train = np.concatenate(x_train_list, axis=0).astype(np.float32)\n",
    "    y_train = np.array(y_train_list, dtype=np.int32)\n",
    "    \n",
    "    # Load test data\n",
    "    test_file_path = os.path.join(data_dir, 'test_batch')\n",
    "    with open(test_file_path, 'rb') as file:\n",
    "        test_batch = pickle.load(file, encoding='bytes')\n",
    "        x_test = test_batch[b'data'].astype(np.float32)\n",
    "        y_test = np.array(test_batch[b'labels'], dtype=np.int32)\n",
    "    \n",
    "    # Normalize the data to [0, 1] range by dividing by 255.0\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_vaild_split(x_train, y_train, split_index=45000):\n",
    "    \"\"\" Split the original training data into a new training dataset\n",
    "        and a validation dataset.\n",
    "    \n",
    "    Args:\n",
    "        x_train: An array of shape [50000, 3072].\n",
    "        y_train: An array of shape [50000,].\n",
    "        split_index: An integer.\n",
    "\n",
    "    Returns:\n",
    "        x_train_new: An array of shape [split_index, 3072].\n",
    "        y_train_new: An array of shape [split_index,].\n",
    "        x_valid: An array of shape [50000-split_index, 3072].\n",
    "        y_valid: An array of shape [50000-split_index,].\n",
    "    \"\"\"\n",
    "    x_train_new = x_train[:split_index]\n",
    "    y_train_new = y_train[:split_index]\n",
    "    x_valid = x_train[split_index:]\n",
    "    y_valid = y_train[split_index:]\n",
    "\n",
    "    return x_train_new, y_train_new, x_valid, y_valid\n",
    "\n",
    "\n",
    "# wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# # Usage\n",
    "# file_path = '/home/grads/s/skpaul/Deep-ResNet-CIFAR-10/cifar-10-python.tar.gz'  # Update with the correct path\n",
    "# extract_dir = '/home/grads/s/skpaul/Deep-ResNet-CIFAR-10/dataset'  # Directory where you want to extract files\n",
    "\n",
    "# # Step 1: Extract the CIFAR-10 dataset\n",
    "# extract_data(file_path, extract_dir)\n",
    "\n",
    "# # Step 2: Load the data\n",
    "# data_dir = os.path.join(extract_dir, 'cifar-10-batches-py')  # Adjust if needed\n",
    "# x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "\n",
    "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "# print(x_train_new.shape, y_train_new.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Data ---\n",
      "(45000, 3072) (45000,) (5000, 3072) (5000,) (10000, 3072) (10000,)\n",
      "cuda\n",
      "--- Starting Training ---\n",
      "### Training... ###\n",
      "Epoch 1 Loss 2.039710 Duration 10.385 seconds.\n",
      "Epoch 2 Loss 1.517706 Duration 10.019 seconds.\n",
      "Epoch 3 Loss 1.311612 Duration 10.391 seconds.\n",
      "Epoch 4 Loss 1.196401 Duration 10.087 seconds.\n",
      "Epoch 5 Loss 1.130557 Duration 9.901 seconds.\n",
      "Epoch 6 Loss 1.085166 Duration 10.096 seconds.\n",
      "Epoch 7 Loss 1.052790 Duration 9.980 seconds.\n",
      "Epoch 8 Loss 1.026934 Duration 9.999 seconds.\n",
      "Epoch 9 Loss 1.014095 Duration 10.015 seconds.\n",
      "Epoch 10 Loss 0.988817 Duration 9.887 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 11 Loss 0.906860 Duration 9.693 seconds.\n",
      "Epoch 12 Loss 0.904237 Duration 9.965 seconds.\n",
      "Epoch 13 Loss 0.885455 Duration 10.135 seconds.\n",
      "Epoch 14 Loss 0.873533 Duration 10.110 seconds.\n",
      "Epoch 15 Loss 0.867581 Duration 10.020 seconds.\n",
      "Epoch 16 Loss 0.855818 Duration 10.226 seconds.\n",
      "Epoch 17 Loss 0.848894 Duration 9.983 seconds.\n",
      "Epoch 18 Loss 0.843844 Duration 10.119 seconds.\n",
      "Epoch 19 Loss 0.833415 Duration 9.898 seconds.\n",
      "Epoch 20 Loss 0.831832 Duration 10.281 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 21 Loss 0.773656 Duration 9.994 seconds.\n",
      "Epoch 22 Loss 0.758803 Duration 9.775 seconds.\n",
      "Epoch 23 Loss 0.760056 Duration 9.929 seconds.\n",
      "Epoch 24 Loss 0.752372 Duration 10.240 seconds.\n",
      "Epoch 25 Loss 0.751016 Duration 10.302 seconds.\n",
      "Epoch 26 Loss 0.741265 Duration 10.206 seconds.\n",
      "Epoch 27 Loss 0.738560 Duration 9.972 seconds.\n",
      "Epoch 28 Loss 0.738756 Duration 10.335 seconds.\n",
      "Epoch 29 Loss 0.733867 Duration 10.105 seconds.\n",
      "Epoch 30 Loss 0.736274 Duration 10.001 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 31 Loss 0.681761 Duration 10.443 seconds.\n",
      "Epoch 32 Loss 0.673426 Duration 10.271 seconds.\n",
      "Epoch 33 Loss 0.664983 Duration 10.363 seconds.\n",
      "Epoch 34 Loss 0.664423 Duration 10.249 seconds.\n",
      "Epoch 35 Loss 0.656438 Duration 10.342 seconds.\n",
      "Epoch 36 Loss 0.656256 Duration 10.379 seconds.\n",
      "Epoch 37 Loss 0.659840 Duration 10.306 seconds.\n",
      "Epoch 38 Loss 0.653878 Duration 10.191 seconds.\n",
      "Epoch 39 Loss 0.645333 Duration 10.533 seconds.\n",
      "Epoch 40 Loss 0.651623 Duration 10.316 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 41 Loss 0.606397 Duration 9.855 seconds.\n",
      "Epoch 42 Loss 0.601746 Duration 10.014 seconds.\n",
      "Epoch 43 Loss 0.598438 Duration 9.884 seconds.\n",
      "Epoch 44 Loss 0.588081 Duration 10.005 seconds.\n",
      "Epoch 45 Loss 0.587719 Duration 10.056 seconds.\n",
      "Epoch 46 Loss 0.591396 Duration 9.987 seconds.\n",
      "Epoch 47 Loss 0.587291 Duration 10.449 seconds.\n",
      "Epoch 48 Loss 0.580962 Duration 10.293 seconds.\n",
      "Epoch 49 Loss 0.582221 Duration 10.012 seconds.\n",
      "Epoch 50 Loss 0.584042 Duration 9.778 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 51 Loss 0.548376 Duration 9.861 seconds.\n",
      "Epoch 52 Loss 0.545637 Duration 10.370 seconds.\n",
      "Epoch 53 Loss 0.540031 Duration 9.779 seconds.\n",
      "Epoch 54 Loss 0.531363 Duration 10.185 seconds.\n",
      "Epoch 55 Loss 0.531557 Duration 10.183 seconds.\n",
      "Epoch 56 Loss 0.533299 Duration 10.657 seconds.\n",
      "Epoch 57 Loss 0.535906 Duration 10.629 seconds.\n",
      "Epoch 58 Loss 0.532563 Duration 10.746 seconds.\n",
      "Epoch 59 Loss 0.523847 Duration 10.366 seconds.\n",
      "Epoch 60 Loss 0.526312 Duration 9.807 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 61 Loss 0.506366 Duration 10.404 seconds.\n",
      "Epoch 62 Loss 0.499451 Duration 10.209 seconds.\n",
      "Epoch 63 Loss 0.495215 Duration 10.257 seconds.\n",
      "Epoch 64 Loss 0.491165 Duration 10.095 seconds.\n",
      "Epoch 65 Loss 0.493714 Duration 10.183 seconds.\n",
      "Epoch 66 Loss 0.487291 Duration 10.141 seconds.\n",
      "Epoch 67 Loss 0.489349 Duration 10.168 seconds.\n",
      "Epoch 68 Loss 0.490160 Duration 9.993 seconds.\n",
      "Epoch 69 Loss 0.485498 Duration 10.012 seconds.\n",
      "Epoch 70 Loss 0.480028 Duration 10.005 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 71 Loss 0.468284 Duration 10.071 seconds.\n",
      "Epoch 72 Loss 0.461439 Duration 10.400 seconds.\n",
      "Epoch 73 Loss 0.460198 Duration 10.156 seconds.\n",
      "Epoch 74 Loss 0.457659 Duration 9.952 seconds.\n",
      "Epoch 75 Loss 0.451110 Duration 9.978 seconds.\n",
      "Epoch 76 Loss 0.453221 Duration 10.272 seconds.\n",
      "Epoch 77 Loss 0.451340 Duration 10.087 seconds.\n",
      "Epoch 78 Loss 0.454075 Duration 9.879 seconds.\n",
      "Epoch 79 Loss 0.452400 Duration 10.030 seconds.\n",
      "Epoch 80 Loss 0.450508 Duration 10.405 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 81 Loss 0.435901 Duration 10.097 seconds.\n",
      "Epoch 82 Loss 0.434370 Duration 10.238 seconds.\n",
      "Epoch 83 Loss 0.431847 Duration 9.917 seconds.\n",
      "Epoch 84 Loss 0.430154 Duration 10.228 seconds.\n",
      "Epoch 85 Loss 0.427571 Duration 10.275 seconds.\n",
      "Epoch 86 Loss 0.430255 Duration 10.068 seconds.\n",
      "Epoch 87 Loss 0.425233 Duration 10.571 seconds.\n",
      "Epoch 88 Loss 0.428024 Duration 10.554 seconds.\n",
      "Epoch 89 Loss 0.419566 Duration 10.025 seconds.\n",
      "Epoch 90 Loss 0.422094 Duration 10.007 seconds.\n",
      "Checkpoint has been created.\n",
      "Epoch 91 Loss 0.410601 Duration 10.144 seconds.\n",
      "Epoch 92 Loss 0.409670 Duration 9.888 seconds.\n",
      "Epoch 93 Loss 0.411697 Duration 9.655 seconds.\n",
      "Epoch 94 Loss 0.405892 Duration 9.683 seconds.\n",
      "Epoch 95 Loss 0.402848 Duration 9.505 seconds.\n",
      "Epoch 96 Loss 0.404483 Duration 9.806 seconds.\n",
      "Epoch 97 Loss 0.402343 Duration 10.065 seconds.\n",
      "Epoch 98 Loss 0.406787 Duration 10.255 seconds.\n",
      "Epoch 99 Loss 0.408114 Duration 10.286 seconds.\n",
      "Epoch 100 Loss 0.403170 Duration 10.317 seconds.\n",
      "Checkpoint has been created.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validating on Validation Set ---\n",
      "### Test or Validation ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3910070/2409967368.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(checkpoint_name, map_location=self.config.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model parameters from model_v2/model-80.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [00:05<00:00, 914.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 80 Test accuracy: 0.8010\n",
      "Restored model parameters from model_v2/model-90.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [00:05<00:00, 914.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 90 Test accuracy: 0.8016\n",
      "Restored model parameters from model_v2/model-100.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [00:05<00:00, 910.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 100 Test accuracy: 0.8084\n",
      "--- Testing on Test Set ---\n",
      "### Test or Validation ###\n",
      "Restored model parameters from model_v2/model-100.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:10<00:00, 915.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 100 Test accuracy: 0.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from ImageUtils import parse_record\n",
    "#from DataReader import load_data, train_vaild_split\n",
    "#from Model import Cifar\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "def configure():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Basic model and training parameters\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128, help='training batch size')\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=10, help='number of classes')\n",
    "    parser.add_argument(\"--save_interval\", type=int, default=10, help='save checkpoint every save_interval epochs')\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=2e-4, help='weight decay rate')\n",
    "    parser.add_argument(\"--modeldir\", type=str, default='model_v2', help='directory for saving models')\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01, help='learning rate')\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0, help='GPU ID to use')\n",
    "    parser.add_argument(\"--use_residual\", type=bool, default=True, help='whether to use residual connections')\n",
    "    parser.add_argument(\"--use_bn\", type=bool, default=True, help='whether to use batch normalization')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "# Parse command-line arguments and configure GPU visibility\n",
    "config = configure()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config.gpu)\n",
    "\n",
    "print(\"--- Preparing Data ---\")\n",
    "\n",
    "# Specify the path to the CIFAR-10 data directory\n",
    "data_dir = \"dataset/cifar-10-batches-py\"  # Update with the actual path to your CIFAR-10 data directory\n",
    "\n",
    "# Load and split the data into training, validation, and test sets\n",
    "x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "print(x_train_new.shape, y_train_new.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and config.gpu >= 0 else \"cpu\")\n",
    "print(device)\n",
    "config.device = device\n",
    "\n",
    "# Initialize the Cifar model with the specified configuration and move it to the selected device\n",
    "model = Cifar(config).to(device)\n",
    "\n",
    "# Train the model for 100 epochs and validate with checkpoints at specified epochs\n",
    "print(\"--- Starting Training ---\")\n",
    "model.train(x_train_new, y_train_new, max_epoch=100)\n",
    "\n",
    "print(\"--- Validating on Validation Set ---\")\n",
    "model.test_or_validate(x_valid, y_valid, checkpoint_num_list=[80, 90, 100])\n",
    "\n",
    "print(\"--- Testing on Test Set ---\")\n",
    "model.test_or_validate(x_test, y_test, checkpoint_num_list=[100])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "#from DataReader import load_data, train_vaild_split\n",
    "#from Model import Cifar\n",
    "\n",
    "def run_experiment(batch_size, save_interval, weight_decay, learning_rate, modeldir, use_residual, use_bn, device):\n",
    "    # Set up config\n",
    "    class Config:\n",
    "        def __init__(self):\n",
    "            self.batch_size = batch_size\n",
    "            self.save_interval = save_interval\n",
    "            self.weight_decay = weight_decay\n",
    "            self.lr = learning_rate\n",
    "            self.modeldir = modeldir\n",
    "            self.use_residual = use_residual\n",
    "            self.use_bn = use_bn\n",
    "            self.device = device\n",
    "    \n",
    "    config = Config()\n",
    "    \n",
    "    # Load and split data\n",
    "    data_dir = \"dataset/cifar-10-batches-py\"\n",
    "    x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "    x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = Cifar(config).to(device)\n",
    "    print(f\"\\n--- Training with learning rate {learning_rate}, Residual: {use_residual}, BatchNorm: {use_bn} ---\")\n",
    "    model.train(x_train_new, y_train_new, 100)\n",
    "\n",
    "    # Validate and test\n",
    "    print(\"\\n--- Validation ---\")\n",
    "    model.test_or_validate(x_valid, y_valid, [80, 90, 100])\n",
    "    print(\"\\n--- Test ---\")\n",
    "    model.test_or_validate(x_test, y_test, [100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directory for saving models\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Define configurations for ResNet variations\n",
    "configs = [\n",
    "    {\"use_residual\": True, \"use_bn\": True, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18\")},\n",
    "    {\"use_residual\": False, \"use_bn\": True, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18_no_residual\")},\n",
    "    {\"use_residual\": True, \"use_bn\": False, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18_no_bn\")}\n",
    "]\n",
    "\n",
    "# Define learning rates to test\n",
    "learning_rates = [0.003, 0.01, 0.03]\n",
    "\n",
    "# Run experiments for each configuration and learning rate\n",
    "for config in configs:\n",
    "    for lr in learning_rates:\n",
    "        run_experiment(\n",
    "            batch_size=128,\n",
    "            save_interval=10,\n",
    "            weight_decay=2e-4,\n",
    "            learning_rate=lr,\n",
    "            modeldir=config[\"modeldir\"],\n",
    "            use_residual=config[\"use_residual\"],\n",
    "            use_bn=config[\"use_bn\"],\n",
    "            device=device\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiemtn to Log and Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_experiment(batch_size, save_interval, weight_decay, learning_rate, modeldir, use_residual, use_bn, device, epochs=100):\n",
    "    class Config:\n",
    "        def __init__(self):\n",
    "            self.batch_size = batch_size\n",
    "            self.save_interval = save_interval\n",
    "            self.weight_decay = weight_decay\n",
    "            self.lr = learning_rate\n",
    "            self.modeldir = modeldir\n",
    "            self.use_residual = use_residual\n",
    "            self.use_bn = use_bn\n",
    "            self.device = device\n",
    "    \n",
    "    config = Config()\n",
    "    \n",
    "    # Load and split data\n",
    "    data_dir = \"dataset/cifar-10-batches-py\"\n",
    "    x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "    x_train_new, y_train_new, x_valid, y_valid = train_vaild_split(x_train, y_train)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = Cifar(config).to(device)\n",
    "    print(f\"\\n--- Training with learning rate {learning_rate}, Residual: {use_residual}, BatchNorm: {use_bn} ---\")\n",
    "\n",
    "    # Track losses\n",
    "    training_losses = []\n",
    "    testing_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training\n",
    "        model.network.train()\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(x_train_new), config.batch_size):\n",
    "            batch_x = torch.tensor(x_train_new[i:i + config.batch_size], dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(y_train_new[i:i + config.batch_size], dtype=torch.long).to(device)\n",
    "            model.optimizer.zero_grad()\n",
    "            logits = model.network(batch_x)\n",
    "            loss = model.loss_fn(logits, batch_y)\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_training_loss = epoch_loss / (len(x_train_new) // config.batch_size)\n",
    "        training_losses.append(avg_training_loss)\n",
    "        print(f\"Epoch {epoch}/{epochs}, Training Loss: {avg_training_loss:.4f}\")\n",
    "\n",
    "        # Testing loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            model.network.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                for i in range(0, len(x_test), config.batch_size):\n",
    "                    batch_x = torch.tensor(x_test[i:i + config.batch_size], dtype=torch.float32).to(device)\n",
    "                    batch_y = torch.tensor(y_test[i:i + config.batch_size], dtype=torch.long).to(device)\n",
    "                    logits = model.network(batch_x)\n",
    "                    loss = model.loss_fn(logits, batch_y)\n",
    "                    test_loss += loss.item()\n",
    "                avg_testing_loss = test_loss / (len(x_test) // config.batch_size)\n",
    "                testing_losses.append(avg_testing_loss)\n",
    "                print(f\"Epoch {epoch}/{epochs}, Testing Loss: {avg_testing_loss:.4f}\")\n",
    "\n",
    "        model.scheduler.step()\n",
    "\n",
    "    # Final testing accuracy\n",
    "    model.network.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for i in range(len(x_test)):\n",
    "            record = torch.tensor(x_test[i], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            label = torch.tensor(y_test[i], dtype=torch.long).to(device)\n",
    "            logits = model.network(record)\n",
    "            pred = logits.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        final_accuracy = correct / len(x_test)\n",
    "        print(f\"\\nFinal Testing Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "    # Plot training and testing loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epochs + 1), training_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(10, epochs + 1, 10), testing_losses, label=\"Testing Loss\", marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Loss Curves - Residual: {use_residual}, BatchNorm: {use_bn}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return final_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the best hyperparameters from previous experiments\n",
    "learning_rate_best = 0.01  # Replace with your best learning rate\n",
    "batch_size_best = 128\n",
    "weight_decay_best = 2e-4\n",
    "save_interval_best = 10\n",
    "epochs = 100\n",
    "\n",
    "# Directory for saving models\n",
    "MODEL_DIR = \"models_best\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Run experiments for each configuration with best hyperparameters\n",
    "configs = [\n",
    "    {\"use_residual\": True, \"use_bn\": True, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18_best\")},\n",
    "    {\"use_residual\": False, \"use_bn\": True, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18_no_residual_best\")},\n",
    "    {\"use_residual\": True, \"use_bn\": False, \"modeldir\": os.path.join(MODEL_DIR, \"resnet18_no_bn_best\")}\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nRunning experiment with Residual: {config['use_residual']}, BatchNorm: {config['use_bn']}\")\n",
    "    final_accuracy = run_experiment(\n",
    "        batch_size=batch_size_best,\n",
    "        save_interval=save_interval_best,\n",
    "        weight_decay=weight_decay_best,\n",
    "        learning_rate=learning_rate_best,\n",
    "        modeldir=config[\"modeldir\"],\n",
    "        use_residual=config[\"use_residual\"],\n",
    "        use_bn=config[\"use_bn\"],\n",
    "        device=device,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    print(f\"Final Testing Accuracy for Residual: {config['use_residual']}, BatchNorm: {config['use_bn']} is {final_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
